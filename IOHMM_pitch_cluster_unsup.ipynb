{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "534b178d",
   "metadata": {},
   "source": [
    "* jaccard係数でクラスタリングしたクラスタ0で教師なしで学習\n",
    "* 事前知識を入れている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e4876d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import resource\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e406312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IOHMM import SemiSupervisedIOHMM\n",
    "from IOHMM import CrossEntropyMNL, DiscreteMNL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ada6036d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- smoothing を加えた DiscreteMNL ---\n",
    "class SmoothedDiscreteMNL(DiscreteMNL):\n",
    "    def __init__(self, solver='lbfgs', alpha=1.0, **kw):\n",
    "        super().__init__(solver=solver, **kw)\n",
    "        self.alpha = alpha\n",
    "    def predict_log_proba(self, X):\n",
    "        logp = super().predict_log_proba(X)\n",
    "        if self.alpha == 0:\n",
    "            return logp \n",
    "        p = np.exp(logp)\n",
    "        p += self.alpha\n",
    "        p /= p.sum(axis=1, keepdims=True)\n",
    "        return np.log(p)\n",
    "    def loglike_per_sample(self, X, y):\n",
    "        y_idx = y.ravel().astype(int)\n",
    "        lp = self.predict_log_proba(X)\n",
    "        return lp[np.arange(len(y_idx)), y_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf2ced4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 09:41:58,068 INFO RLIMIT_AS=32000MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 09:44:49,673 INFO log likelihood of iteration 0: -1067142.5595\n",
      "2025-07-01 09:46:31,344 INFO log likelihood of iteration 1: -1067142.1959\n",
      "2025-07-01 09:48:12,870 INFO log likelihood of iteration 2: -1067141.5350\n",
      "2025-07-01 09:49:54,119 INFO log likelihood of iteration 3: -1067140.3184\n",
      "2025-07-01 09:51:36,953 INFO log likelihood of iteration 4: -1067138.1902\n",
      "2025-07-01 09:53:21,248 INFO log likelihood of iteration 5: -1067133.8802\n",
      "2025-07-01 09:55:01,264 INFO log likelihood of iteration 6: -1067128.8004\n",
      "2025-07-01 09:56:42,664 INFO log likelihood of iteration 7: -1067107.1711\n",
      "2025-07-01 09:58:23,098 INFO log likelihood of iteration 8: -1067056.3306\n",
      "2025-07-01 10:00:00,855 INFO log likelihood of iteration 9: -1066957.1319\n",
      "2025-07-01 10:01:43,329 INFO log likelihood of iteration 10: -1066724.9415\n",
      "2025-07-01 10:03:23,329 INFO log likelihood of iteration 11: -1066208.1014\n",
      "2025-07-01 10:05:04,308 INFO log likelihood of iteration 12: -1065126.0123\n",
      "2025-07-01 10:06:46,093 INFO log likelihood of iteration 13: -1063022.4401\n",
      "2025-07-01 10:08:31,528 INFO log likelihood of iteration 14: -1059619.1250\n",
      "2025-07-01 10:10:18,698 INFO log likelihood of iteration 15: -1055272.4834\n",
      "2025-07-01 10:12:06,849 INFO log likelihood of iteration 16: -1050923.6465\n",
      "2025-07-01 10:13:56,736 INFO log likelihood of iteration 17: -1047312.5832\n",
      "2025-07-01 10:15:44,814 INFO log likelihood of iteration 18: -1044496.3739\n",
      "2025-07-01 10:17:33,920 INFO log likelihood of iteration 19: -1042298.6964\n",
      "2025-07-01 10:19:25,843 INFO log likelihood of iteration 20: -1040530.3974\n",
      "2025-07-01 10:21:15,637 INFO log likelihood of iteration 21: -1039133.2505\n",
      "2025-07-01 10:23:09,591 INFO log likelihood of iteration 22: -1038056.4697\n",
      "2025-07-01 10:25:00,751 INFO log likelihood of iteration 23: -1037281.5057\n",
      "2025-07-01 10:26:52,182 INFO log likelihood of iteration 24: -1036743.6948\n",
      "2025-07-01 10:28:42,114 INFO log likelihood of iteration 25: -1036363.4993\n",
      "2025-07-01 10:30:39,162 INFO log likelihood of iteration 26: -1036095.8364\n",
      "2025-07-01 10:32:30,266 INFO log likelihood of iteration 27: -1035886.5185\n",
      "2025-07-01 10:34:19,473 INFO log likelihood of iteration 28: -1035727.6435\n",
      "2025-07-01 10:36:10,852 INFO log likelihood of iteration 29: -1035591.7023\n",
      "2025-07-01 10:38:05,576 INFO log likelihood of iteration 30: -1035457.7648\n",
      "2025-07-01 10:39:58,865 INFO log likelihood of iteration 31: -1035341.1023\n",
      "2025-07-01 10:41:47,533 INFO log likelihood of iteration 32: -1035220.7974\n",
      "2025-07-01 10:43:41,413 INFO log likelihood of iteration 33: -1035094.5443\n",
      "2025-07-01 10:45:33,891 INFO log likelihood of iteration 34: -1034957.4645\n",
      "2025-07-01 10:47:25,809 INFO log likelihood of iteration 35: -1034791.3137\n",
      "2025-07-01 10:49:16,474 INFO log likelihood of iteration 36: -1034614.9902\n",
      "2025-07-01 10:51:11,473 INFO log likelihood of iteration 37: -1034395.4995\n",
      "2025-07-01 10:53:02,487 INFO log likelihood of iteration 38: -1034104.3922\n",
      "2025-07-01 10:54:58,409 INFO log likelihood of iteration 39: -1033748.0035\n",
      "2025-07-01 10:56:52,559 INFO log likelihood of iteration 40: -1033252.5698\n",
      "2025-07-01 10:58:45,337 INFO log likelihood of iteration 41: -1032524.2724\n",
      "2025-07-01 11:00:40,184 INFO log likelihood of iteration 42: -1031466.2364\n",
      "2025-07-01 11:02:37,365 INFO log likelihood of iteration 43: -1029947.7800\n",
      "2025-07-01 11:04:30,401 INFO log likelihood of iteration 44: -1027949.2513\n",
      "2025-07-01 11:06:23,088 INFO log likelihood of iteration 45: -1025350.8114\n",
      "2025-07-01 11:08:15,814 INFO log likelihood of iteration 46: -1022168.4954\n",
      "2025-07-01 11:10:10,824 INFO log likelihood of iteration 47: -1018458.4926\n",
      "2025-07-01 11:12:06,679 INFO log likelihood of iteration 48: -1014130.9549\n",
      "2025-07-01 11:14:04,438 INFO log likelihood of iteration 49: -1008946.3647\n",
      "2025-07-01 11:16:04,128 INFO log likelihood of iteration 50: -1002894.9821\n",
      "2025-07-01 11:18:03,931 INFO log likelihood of iteration 51: -996561.6186\n",
      "2025-07-01 11:20:06,560 INFO log likelihood of iteration 52: -990584.2477\n",
      "2025-07-01 11:22:11,644 INFO log likelihood of iteration 53: -985134.4853\n",
      "2025-07-01 11:24:28,372 INFO log likelihood of iteration 54: -980301.2971\n",
      "2025-07-01 11:26:43,577 INFO log likelihood of iteration 55: -976127.2640\n",
      "2025-07-01 11:28:57,462 INFO log likelihood of iteration 56: -972730.2866\n",
      "2025-07-01 11:31:05,255 INFO log likelihood of iteration 57: -970146.7899\n",
      "2025-07-01 11:33:16,303 INFO log likelihood of iteration 58: -968142.9794\n",
      "2025-07-01 11:35:24,911 INFO log likelihood of iteration 59: -966564.7657\n",
      "2025-07-01 11:37:32,323 INFO log likelihood of iteration 60: -965269.9995\n",
      "2025-07-01 11:39:42,559 INFO log likelihood of iteration 61: -964217.3912\n",
      "2025-07-01 11:41:53,709 INFO log likelihood of iteration 62: -963403.9466\n",
      "2025-07-01 11:44:02,930 INFO log likelihood of iteration 63: -962739.4903\n",
      "2025-07-01 11:46:14,512 INFO log likelihood of iteration 64: -962183.8230\n",
      "2025-07-01 11:48:23,212 INFO log likelihood of iteration 65: -961710.8378\n",
      "2025-07-01 11:50:30,427 INFO log likelihood of iteration 66: -961283.1133\n",
      "2025-07-01 11:52:46,174 INFO log likelihood of iteration 67: -960946.5003\n",
      "2025-07-01 11:54:56,714 INFO log likelihood of iteration 68: -960639.0010\n",
      "2025-07-01 11:57:10,209 INFO log likelihood of iteration 69: -960349.0834\n",
      "2025-07-01 11:59:21,441 INFO log likelihood of iteration 70: -960057.9239\n",
      "2025-07-01 12:01:33,597 INFO log likelihood of iteration 71: -959789.7198\n",
      "2025-07-01 12:03:45,096 INFO log likelihood of iteration 72: -959559.0782\n",
      "2025-07-01 12:06:01,575 INFO log likelihood of iteration 73: -959358.3856\n",
      "2025-07-01 12:08:09,327 INFO log likelihood of iteration 74: -959160.8027\n",
      "2025-07-01 12:10:24,215 INFO log likelihood of iteration 75: -958982.3713\n",
      "2025-07-01 12:12:34,158 INFO log likelihood of iteration 76: -958816.8094\n",
      "2025-07-01 12:14:45,043 INFO log likelihood of iteration 77: -958649.4499\n",
      "2025-07-01 12:16:57,645 INFO log likelihood of iteration 78: -958526.4097\n",
      "2025-07-01 12:19:06,346 INFO log likelihood of iteration 79: -958382.7876\n",
      "2025-07-01 12:21:14,961 INFO log likelihood of iteration 80: -958233.9645\n",
      "2025-07-01 12:23:19,644 INFO log likelihood of iteration 81: -958092.6326\n",
      "2025-07-01 12:25:28,862 INFO log likelihood of iteration 82: -957935.2942\n",
      "2025-07-01 12:27:37,301 INFO log likelihood of iteration 83: -957758.1307\n",
      "2025-07-01 12:29:47,170 INFO log likelihood of iteration 84: -957594.6697\n",
      "2025-07-01 12:31:55,506 INFO log likelihood of iteration 85: -957397.0571\n",
      "2025-07-01 12:34:04,494 INFO log likelihood of iteration 86: -957223.3741\n",
      "2025-07-01 12:36:13,270 INFO log likelihood of iteration 87: -957054.9890\n",
      "2025-07-01 12:38:21,218 INFO log likelihood of iteration 88: -956886.2468\n",
      "2025-07-01 12:40:35,959 INFO log likelihood of iteration 89: -956711.7535\n",
      "2025-07-01 12:42:44,805 INFO log likelihood of iteration 90: -956557.4223\n",
      "2025-07-01 12:44:53,090 INFO log likelihood of iteration 91: -956413.7617\n",
      "2025-07-01 12:47:02,273 INFO log likelihood of iteration 92: -956282.0651\n",
      "2025-07-01 12:49:08,970 INFO log likelihood of iteration 93: -956163.9932\n",
      "2025-07-01 12:51:17,159 INFO log likelihood of iteration 94: -956055.2637\n",
      "2025-07-01 12:53:24,763 INFO log likelihood of iteration 95: -955951.7488\n",
      "2025-07-01 12:55:28,993 INFO log likelihood of iteration 96: -955846.2896\n",
      "2025-07-01 12:57:33,393 INFO log likelihood of iteration 97: -955730.6621\n",
      "2025-07-01 12:59:36,668 INFO log likelihood of iteration 98: -955628.6604\n",
      "2025-07-01 13:01:42,114 INFO log likelihood of iteration 99: -955543.4263\n",
      "2025-07-01 13:03:47,479 INFO log likelihood of iteration 100: -955432.9110\n",
      "2025-07-01 13:05:56,775 INFO log likelihood of iteration 101: -955336.9644\n",
      "2025-07-01 13:08:09,394 INFO log likelihood of iteration 102: -955239.1547\n",
      "2025-07-01 13:10:22,701 INFO log likelihood of iteration 103: -955150.4165\n",
      "2025-07-01 13:12:39,762 INFO log likelihood of iteration 104: -955067.7386\n",
      "2025-07-01 13:14:45,514 INFO log likelihood of iteration 105: -954974.5090\n",
      "2025-07-01 13:16:51,652 INFO log likelihood of iteration 106: -954863.7812\n",
      "2025-07-01 13:19:08,673 INFO log likelihood of iteration 107: -954780.5116\n",
      "2025-07-01 13:21:19,662 INFO log likelihood of iteration 108: -954699.9623\n",
      "2025-07-01 13:23:31,718 INFO log likelihood of iteration 109: -954606.3883\n",
      "2025-07-01 13:25:49,585 INFO log likelihood of iteration 110: -954505.5270\n",
      "2025-07-01 13:27:59,060 INFO log likelihood of iteration 111: -954397.7487\n",
      "2025-07-01 13:30:19,247 INFO log likelihood of iteration 112: -954260.4058\n",
      "2025-07-01 13:32:31,804 INFO log likelihood of iteration 113: -954072.3495\n",
      "2025-07-01 13:34:38,645 INFO log likelihood of iteration 114: -953876.2865\n",
      "2025-07-01 13:36:43,640 INFO log likelihood of iteration 115: -953674.7477\n",
      "2025-07-01 13:38:45,940 INFO log likelihood of iteration 116: -953456.8016\n",
      "2025-07-01 13:40:53,805 INFO log likelihood of iteration 117: -953250.2496\n",
      "2025-07-01 13:42:57,961 INFO log likelihood of iteration 118: -953047.8403\n",
      "2025-07-01 13:45:01,332 INFO log likelihood of iteration 119: -952858.6019\n",
      "2025-07-01 13:47:08,811 INFO log likelihood of iteration 120: -952643.5718\n",
      "2025-07-01 13:49:11,771 INFO log likelihood of iteration 121: -952446.1520\n",
      "2025-07-01 13:51:19,263 INFO log likelihood of iteration 122: -952259.2074\n",
      "2025-07-01 13:53:28,007 INFO log likelihood of iteration 123: -952092.0657\n",
      "2025-07-01 13:55:37,317 INFO log likelihood of iteration 124: -951898.5038\n",
      "2025-07-01 13:57:43,852 INFO log likelihood of iteration 125: -951694.3506\n",
      "2025-07-01 13:59:54,831 INFO log likelihood of iteration 126: -951496.5511\n",
      "2025-07-01 14:01:56,966 INFO log likelihood of iteration 127: -951303.9821\n",
      "2025-07-01 14:03:58,169 INFO log likelihood of iteration 128: -951127.4096\n",
      "2025-07-01 14:06:00,689 INFO log likelihood of iteration 129: -950944.8451\n",
      "2025-07-01 14:08:04,650 INFO log likelihood of iteration 130: -950770.8893\n",
      "2025-07-01 14:10:13,943 INFO log likelihood of iteration 131: -950605.6606\n",
      "2025-07-01 14:12:25,844 INFO log likelihood of iteration 132: -950423.6035\n",
      "2025-07-01 14:14:26,894 INFO log likelihood of iteration 133: -950271.7255\n",
      "2025-07-01 14:16:29,051 INFO log likelihood of iteration 134: -950122.3377\n",
      "2025-07-01 14:18:37,772 INFO log likelihood of iteration 135: -950019.4198\n",
      "2025-07-01 14:20:48,203 INFO log likelihood of iteration 136: -949864.1774\n",
      "2025-07-01 14:22:52,983 INFO log likelihood of iteration 137: -949743.9275\n",
      "2025-07-01 14:24:52,175 INFO log likelihood of iteration 138: -949636.3270\n",
      "2025-07-01 14:26:50,175 INFO log likelihood of iteration 139: -949541.0459\n",
      "2025-07-01 14:28:49,574 INFO log likelihood of iteration 140: -949458.4294\n",
      "2025-07-01 14:30:47,391 INFO log likelihood of iteration 141: -949374.7746\n",
      "2025-07-01 14:32:44,006 INFO log likelihood of iteration 142: -949293.9934\n",
      "2025-07-01 14:34:45,501 INFO log likelihood of iteration 143: -949208.4038\n",
      "2025-07-01 14:36:43,350 INFO log likelihood of iteration 144: -949125.0688\n",
      "2025-07-01 14:38:44,078 INFO log likelihood of iteration 145: -949040.3486\n",
      "2025-07-01 14:41:09,947 INFO log likelihood of iteration 146: -948953.7734\n",
      "2025-07-01 14:43:14,432 INFO log likelihood of iteration 147: -948872.5696\n",
      "2025-07-01 14:45:21,438 INFO log likelihood of iteration 148: -948783.3090\n",
      "2025-07-01 14:47:27,189 INFO log likelihood of iteration 149: -948699.1351\n",
      "2025-07-01 14:49:25,691 INFO log likelihood of iteration 150: -948608.6036\n",
      "2025-07-01 14:51:26,743 INFO log likelihood of iteration 151: -948522.4344\n",
      "2025-07-01 14:53:28,412 INFO log likelihood of iteration 152: -948448.0220\n",
      "2025-07-01 14:55:28,335 INFO log likelihood of iteration 153: -948368.9360\n",
      "2025-07-01 14:57:30,411 INFO log likelihood of iteration 154: -948291.1876\n",
      "2025-07-01 14:59:30,714 INFO log likelihood of iteration 155: -948205.3186\n",
      "2025-07-01 15:01:31,025 INFO log likelihood of iteration 156: -948118.7928\n",
      "2025-07-01 15:03:31,200 INFO log likelihood of iteration 157: -948032.4872\n",
      "2025-07-01 15:05:29,578 INFO log likelihood of iteration 158: -947952.0649\n",
      "2025-07-01 15:07:29,722 INFO log likelihood of iteration 159: -947861.0057\n",
      "2025-07-01 15:09:29,119 INFO log likelihood of iteration 160: -947780.9222\n",
      "2025-07-01 15:11:28,582 INFO log likelihood of iteration 161: -947702.8621\n",
      "2025-07-01 15:13:28,835 INFO log likelihood of iteration 162: -947624.3359\n",
      "2025-07-01 15:15:29,335 INFO log likelihood of iteration 163: -947561.7265\n",
      "2025-07-01 15:17:30,052 INFO log likelihood of iteration 164: -947508.7205\n",
      "2025-07-01 15:19:31,969 INFO log likelihood of iteration 165: -947445.0071\n",
      "2025-07-01 15:21:32,489 INFO log likelihood of iteration 166: -947386.5881\n",
      "2025-07-01 15:23:33,252 INFO log likelihood of iteration 167: -947329.1681\n",
      "2025-07-01 15:25:34,843 INFO log likelihood of iteration 168: -947265.8560\n",
      "2025-07-01 15:27:35,089 INFO log likelihood of iteration 169: -947204.1515\n",
      "2025-07-01 15:29:37,744 INFO log likelihood of iteration 170: -947153.1639\n",
      "2025-07-01 15:31:38,252 INFO log likelihood of iteration 171: -947096.9569\n",
      "2025-07-01 15:33:37,720 INFO log likelihood of iteration 172: -947044.7655\n",
      "2025-07-01 15:35:41,137 INFO log likelihood of iteration 173: -946992.6109\n",
      "2025-07-01 15:37:40,630 INFO log likelihood of iteration 174: -946935.1269\n",
      "2025-07-01 15:39:43,417 INFO log likelihood of iteration 175: -946870.9544\n",
      "2025-07-01 15:41:46,530 INFO log likelihood of iteration 176: -946806.6087\n",
      "2025-07-01 15:43:46,944 INFO log likelihood of iteration 177: -946743.1662\n",
      "2025-07-01 15:45:45,861 INFO log likelihood of iteration 178: -946657.5306\n",
      "2025-07-01 15:47:45,509 INFO log likelihood of iteration 179: -946565.5601\n",
      "2025-07-01 15:49:42,462 INFO log likelihood of iteration 180: -946469.4323\n",
      "2025-07-01 15:51:42,737 INFO log likelihood of iteration 181: -946343.3967\n",
      "2025-07-01 15:53:41,548 INFO log likelihood of iteration 182: -946177.7005\n",
      "2025-07-01 15:55:45,005 INFO log likelihood of iteration 183: -945980.6551\n",
      "2025-07-01 15:57:45,485 INFO log likelihood of iteration 184: -945748.1367\n",
      "2025-07-01 15:59:46,037 INFO log likelihood of iteration 185: -945492.5213\n",
      "2025-07-01 16:01:44,966 INFO log likelihood of iteration 186: -945210.9857\n",
      "2025-07-01 16:03:45,380 INFO log likelihood of iteration 187: -944941.6878\n",
      "2025-07-01 16:05:46,153 INFO log likelihood of iteration 188: -944681.5761\n",
      "2025-07-01 16:07:45,774 INFO log likelihood of iteration 189: -944473.1404\n",
      "2025-07-01 16:09:46,647 INFO log likelihood of iteration 190: -944285.7464\n",
      "2025-07-01 16:11:44,017 INFO log likelihood of iteration 191: -944159.2179\n",
      "2025-07-01 16:13:44,385 INFO log likelihood of iteration 192: -944049.0073\n",
      "2025-07-01 16:15:42,484 INFO log likelihood of iteration 193: -943946.3911\n",
      "2025-07-01 16:17:34,711 INFO log likelihood of iteration 194: -943868.2672\n",
      "2025-07-01 16:19:31,582 INFO log likelihood of iteration 195: -943818.3211\n",
      "2025-07-01 16:21:28,286 INFO log likelihood of iteration 196: -943763.2318\n",
      "2025-07-01 16:23:29,352 INFO log likelihood of iteration 197: -943724.5627\n",
      "2025-07-01 16:25:28,464 INFO log likelihood of iteration 198: -943685.5022\n",
      "2025-07-01 16:27:27,365 INFO log likelihood of iteration 199: -943640.6982\n",
      "2025-07-01 16:29:27,502 INFO log likelihood of iteration 200: -943614.1756\n"
     ]
    }
   ],
   "source": [
    "# train_iohmm_unsupervised.py\n",
    "# 投球数が多い投手クラスタに対して教師なしIOHMMを学習・保存するスクリプト\n",
    "import os\n",
    "import logging\n",
    "import resource\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IOHMM import SemiSupervisedIOHMM\n",
    "from IOHMM import CrossEntropyMNL, DiscreteMNL\n",
    "\n",
    "# --- メモリ・CPU 制限設定 ---\n",
    "def set_limits(max_mem_mb=None, max_cpu_sec=None):\n",
    "    if max_mem_mb:\n",
    "        mb = max_mem_mb * 1024 * 1024\n",
    "        resource.setrlimit(resource.RLIMIT_AS, (mb, mb))\n",
    "        logging.info(f\"RLIMIT_AS={max_mem_mb}MB\")\n",
    "    if max_cpu_sec:\n",
    "        resource.setrlimit(resource.RLIMIT_CPU, (max_cpu_sec, max_cpu_sec))\n",
    "        logging.info(f\"RLIMIT_CPU={max_cpu_sec}s\")\n",
    "\n",
    "# --- smoothing を加えた DiscreteMNL ---\n",
    "class SmoothedDiscreteMNL(DiscreteMNL):\n",
    "    def __init__(self, solver='lbfgs', alpha=1.0, **kw):\n",
    "        super().__init__(solver=solver, **kw)\n",
    "        self.alpha = alpha\n",
    "    def predict_log_proba(self, X):\n",
    "        logp = super().predict_log_proba(X)\n",
    "        if self.alpha == 0:\n",
    "            return logp \n",
    "        p = np.exp(logp)\n",
    "        p += self.alpha\n",
    "        p /= p.sum(axis=1, keepdims=True)\n",
    "        return np.log(p)\n",
    "    def loglike_per_sample(self, X, y):\n",
    "        y_idx = y.ravel().astype(int)\n",
    "        lp = self.predict_log_proba(X)\n",
    "        return lp[np.arange(len(y_idx)), y_idx]\n",
    "\n",
    "def prepare_dfs_unsupervised(df_p, test_size=0.2, random_state=42):\n",
    "    req = ['balls','strikes','pitch_type','zone_cluster','pitch_cluster_label','zone','pitcher','game_pk']\n",
    "    missing = [c for c in req if c not in df_p.columns]\n",
    "    if missing:\n",
    "        raise RuntimeError(f\"Missing columns: {missing}\")\n",
    "    df = df_p.dropna(subset=['pitch_cluster_label','zone_cluster']).reset_index(drop=True)\n",
    "\n",
    "    # ラベルエンコーダーを作成\n",
    "    global le_zcl, le_z, le_pcl\n",
    "    le_zcl = LabelEncoder().fit(df['zone_cluster'])\n",
    "    le_z   = LabelEncoder().fit(df['zone'])\n",
    "    le_pcl = LabelEncoder().fit(df['pitch_cluster_label'])\n",
    "\n",
    "    # 数値変換\n",
    "    df['zone_cluster']         = le_zcl.transform(df['zone_cluster'])\n",
    "    df['zone']                 = le_z.transform(df['zone'])\n",
    "    df['pitch_cluster_label']  = le_pcl.transform(df['pitch_cluster_label'])\n",
    "\n",
    "    # ワンホット化（balls, strikes）\n",
    "    all_combinations = [[b, s] for b in range(4) for s in range(3)]\n",
    "    ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    ohe.fit(all_combinations)\n",
    "    X_ohe = ohe.transform(df[['balls','strikes']])\n",
    "    input_features = ohe.get_feature_names_out(['balls','strikes'])\n",
    "    df_ohe = pd.DataFrame(X_ohe, columns=input_features)\n",
    "    df = pd.concat([df.reset_index(drop=True), df_ohe], axis=1)\n",
    "\n",
    "    # シーケンス毎に分割\n",
    "    seqs = {f\"{p}_game_{g}\": gdf.reset_index(drop=True)\n",
    "            for (p, g), gdf in df.groupby(['pitcher','game_pk'])\n",
    "            if len(gdf) >= 2}\n",
    "\n",
    "    keys = list(seqs.keys())\n",
    "    train_keys, test_keys = train_test_split(keys, test_size=test_size, random_state=random_state)\n",
    "    dfs_train = [[seqs[k], {}] for k in train_keys]\n",
    "    dfs_test  = [[seqs[k], {}] for k in test_keys]\n",
    "    test_df   = pd.concat([seqs[k] for k in test_keys], axis=0, ignore_index=True)\n",
    "\n",
    "    return dfs_train, dfs_test, test_df, ohe, input_features.tolist()\n",
    "\n",
    "# --- モデル構築と学習（終了条件付きEM） ---\n",
    "def build_and_train(dfs_train,\n",
    "                    num_states,\n",
    "                    input_features,\n",
    "                    save_dir,\n",
    "                    max_iter=500,\n",
    "                    tol=1e-4):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    shmm = SemiSupervisedIOHMM(num_states=num_states,\n",
    "                               EM_tol=tol,\n",
    "                               max_EM_iter=max_iter)\n",
    "\n",
    "    # --- 1) 共通のベース emission モデルを用意 ---\n",
    "    em_pitch_base = SmoothedDiscreteMNL(solver='lbfgs', alpha=0,\n",
    "                                        max_iter=max_iter, tol=tol)\n",
    "    em_zone_base  = SmoothedDiscreteMNL(solver='lbfgs', alpha=0,\n",
    "                                        max_iter=max_iter, tol=tol)\n",
    "\n",
    "    # クラス数・特徴量数を取得\n",
    "    n_pcl = len(le_pcl.classes_)\n",
    "    n_zcl = len(le_zcl.classes_)\n",
    "    n_feat = len(input_features)\n",
    "\n",
    "    # 一様初期化\n",
    "    em_pitch_base.coef_      = np.zeros((n_pcl, n_feat))\n",
    "    em_pitch_base.intercept_ = np.log(np.ones(n_pcl) * (1.0 / n_pcl))\n",
    "\n",
    "    em_zone_base.coef_       = np.zeros((n_zcl, n_feat))\n",
    "    em_zone_base.intercept_  = np.log(np.ones(n_zcl) * (1.0 / n_zcl))\n",
    "\n",
    "    # --- 2) flat list で set_models（内部で状態数分 deep-copy される） ---\n",
    "    shmm.set_models(\n",
    "        model_emissions=[em_pitch_base, em_zone_base],\n",
    "        model_transition=CrossEntropyMNL(solver='lbfgs', max_iter=max_iter, tol=tol),\n",
    "        model_initial=  CrossEntropyMNL(solver='lbfgs', max_iter=max_iter, tol=tol)\n",
    "    )\n",
    "\n",
    "    # --- 3) 状態ごとに事前知識を注入 ---\n",
    "    for st in range(num_states):\n",
    "        # Pitch: 'FF/FC' を 60% にする例\n",
    "        em_p = shmm.model_emissions[st][0]\n",
    "        base_p  = np.log((1 - 0.6) / (n_pcl - 1))\n",
    "        em_p.intercept_[:]        = base_p\n",
    "        if st == 0:\n",
    "            idx_fffc = list(le_pcl.classes_).index('FF/SI')\n",
    "            em_p.intercept_[idx_fffc] = np.log(0.6)#　カウント取りたい\n",
    "        elif st == 1:\n",
    "            idx_fffc = list(le_pcl.classes_).index('SL')\n",
    "            em_p.intercept_[idx_fffc] = np.log(0.6)#　空振り取りたい\n",
    "        elif st == 2:\n",
    "            idx_fffc = list(le_pcl.classes_).index('FF/SI')\n",
    "            em_p.intercept_[idx_fffc] = np.log(0.6)#　打ち取りたい\n",
    "        elif st == 3:\n",
    "            idx_fffc = list(le_pcl.classes_).index('CH')\n",
    "            em_p.intercept_[idx_fffc] = np.log(0.6)#　様子見、ボール球\n",
    "        # Zone: '外角低め' を 60% にする例\n",
    "        em_z = shmm.model_emissions[st][1]\n",
    "        base_z  = np.log((1 - 0.6) / (n_zcl - 1))\n",
    "        em_z.intercept_[:]        = base_z\n",
    "        if st == 0:\n",
    "            idx_zlow = list(le_zcl.classes_).index(1)\n",
    "            em_z.intercept_[idx_zlow] = np.log(0.6)\n",
    "        elif st == 1:\n",
    "            idx_zlow = list(le_zcl.classes_).index(3)\n",
    "            em_z.intercept_[idx_zlow] = np.log(0.6)\n",
    "        elif st == 2:\n",
    "            idx_zlow = list(le_zcl.classes_).index(2)\n",
    "            em_z.intercept_[idx_zlow] = np.log(0.6)\n",
    "        elif st == 3:\n",
    "            idx_zlow = list(le_zcl.classes_).index(3)\n",
    "            em_z.intercept_[idx_zlow] = np.log(0.6)\n",
    "\n",
    "    for st in range(num_states):\n",
    "    # --- 球種の出力確率初期化 ---\n",
    "        em_p = shmm.model_emissions[st][0]\n",
    "        base_p = np.log((1 - 0.6) / (n_pcl - 1))  # ベースを均等に\n",
    "        em_p.intercept_[:] = base_p\n",
    "        \n",
    "        # --- 状態ごとの球種強調 ---\n",
    "        if st == 0:  # ストライク取りたい\n",
    "            idx = list(le_pcl.classes_).index('FF/SI')\n",
    "            em_p.intercept_[idx] = np.log(0.6)\n",
    "        elif st == 1:  # 空振り取りたい\n",
    "            idx = list(le_pcl.classes_).index('SL')\n",
    "            em_p.intercept_[idx] = np.log(0.6)\n",
    "        elif st == 2:  # 打たせてとりたい\n",
    "            idx = list(le_pcl.classes_).index('FF/SI')\n",
    "            em_p.intercept_[idx] = np.log(0.6)\n",
    "        elif st == 3:  # ボール球で様子見\n",
    "            idx = list(le_pcl.classes_).index('CH')\n",
    "            em_p.intercept_[idx] = np.log(0.6)\n",
    "        elif st == 4:  # 三振狙い\n",
    "            idx = list(le_pcl.classes_).index('FF/SI')\n",
    "            em_p.intercept_[idx] = np.log(0.6)\n",
    "        elif st == 5:  # 多彩に散らすカウント整えたい\n",
    "            idx = list(le_pcl.classes_).index('CU')\n",
    "            em_p.intercept_[idx] = np.log(0.6)\n",
    "        \n",
    "        # --- ゾーンの出力確率初期化 ---\n",
    "        em_z = shmm.model_emissions[st][1]\n",
    "        base_z = np.log((1 - 0.6) / (n_zcl - 1))\n",
    "        em_z.intercept_[:] = base_z\n",
    "        \n",
    "        # --- 状態ごとのゾーン強調 ---\n",
    "        if st == 0:\n",
    "            idx = list(le_zcl.classes_).index(0)  # 高め\n",
    "            em_z.intercept_[idx] = np.log(0.6)\n",
    "        elif st == 1:\n",
    "            idx = list(le_zcl.classes_).index(3)  # 外角低め\n",
    "            em_z.intercept_[idx] = np.log(0.6)\n",
    "        elif st == 2:\n",
    "            idx = list(le_zcl.classes_).index(2)  # 内角\n",
    "            em_z.intercept_[idx] = np.log(0.6)\n",
    "        elif st == 3:\n",
    "            idx = list(le_zcl.classes_).index(3)  # 外角低め\n",
    "            em_z.intercept_[idx] = np.log(0.6)\n",
    "        elif st == 4:\n",
    "            idx = list(le_zcl.classes_).index(1)  # 外角\n",
    "            em_z.intercept_[idx] = np.log(0.6)\n",
    "        elif st == 5:\n",
    "            idx = list(le_zcl.classes_).index(1)  # 外角\n",
    "            em_z.intercept_[idx] = np.log(0.6)\n",
    "\n",
    "\n",
    "    # --- 4) 入力・出力の設定および学習 ---\n",
    "    shmm.set_inputs(\n",
    "        covariates_initial=input_features,\n",
    "        covariates_transition=input_features,\n",
    "        covariates_emissions=[input_features, input_features]\n",
    "    )\n",
    "    shmm.set_outputs([['pitch_cluster_label'], ['zone_cluster']])\n",
    "    shmm.set_data(dfs_train)\n",
    "\n",
    "    shmm.train()\n",
    "\n",
    "    # モデル保存\n",
    "    with open(os.path.join(save_dir, 'model.pkl'), 'wb') as f:\n",
    "        pickle.dump(shmm, f)\n",
    "    logging.info(f\"Saved model to {save_dir}/model.pkl | LL={shmm.log_likelihood:.4f}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logging.basicConfig(level=logging.INFO,\n",
    "                        format='%(asctime)s %(levelname)s %(message)s')\n",
    "    set_limits(max_mem_mb=32000)\n",
    "\n",
    "    df_all = pd.read_csv('statcast_pitcher_clster.csv')\n",
    "    df_p   = df_all[df_all['pitcher_cluster'] == 0].copy()\n",
    "\n",
    "    dfs_train, dfs_test, test_df, ohe, input_features = prepare_dfs_unsupervised(df_p)\n",
    "    out_dir = 'iohmm_cluster_0_with_prior_6'\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    test_df.to_csv(os.path.join(out_dir, 'test_data.csv'), index=False)\n",
    "    with open(os.path.join(out_dir, 'encoders.pkl'), 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'le_zone_cluster': le_zcl,\n",
    "            'le_zone': le_z,\n",
    "            'le_pitch_cluster_label': le_pcl,\n",
    "            'ohe_input': ohe,\n",
    "            'input_features': input_features\n",
    "        }, f)\n",
    "\n",
    "    build_and_train(dfs_train,\n",
    "                    num_states=6,\n",
    "                    input_features=input_features,\n",
    "                    save_dir=out_dir,\n",
    "                    max_iter=400,\n",
    "                    tol=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9589bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import ceil\n",
    "\n",
    "# クラスタ番号のリスト（必要なクラスタを指定）\n",
    "cluster_list = [0]  # 必要に応じて変更\n",
    "\n",
    "# balls-strikes 全組み合わせ\n",
    "covs = [(b, s) for b in range(4) for s in range(3)]\n",
    "n_cov = len(covs)\n",
    "n_cols = 3\n",
    "n_rows = ceil(n_cov / n_cols)\n",
    "\n",
    "for cluster in cluster_list:\n",
    "    model_dir = f\"iohmm_cluster_0_with_prior\"\n",
    "    model_fp  = os.path.join(model_dir, \"model.pkl\")\n",
    "    enc_fp    = os.path.join(model_dir, \"encoders.pkl\")\n",
    "\n",
    "    if not os.path.isfile(model_fp) or not os.path.isfile(enc_fp):\n",
    "        print(f\"[Cluster {cluster}] モデルまたはエンコーダが見つかりません。スキップします。\")\n",
    "        continue\n",
    "\n",
    "    with open(model_fp, \"rb\") as mf:\n",
    "        shmm_loaded = pickle.load(mf)\n",
    "    with open(enc_fp, \"rb\") as ef:\n",
    "        encs = pickle.load(ef)\n",
    "\n",
    "    # 隠れ状態ID と表示ラベルを用意\n",
    "    state_ids    = np.arange(shmm_loaded.num_states)\n",
    "    state_labels = [f\"state{st}\" for st in state_ids]\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 4 * n_rows), sharey=True)\n",
    "    axes = axes.flatten()\n",
    "    fig.suptitle(f\"Cluster {cluster} - Initial State Probabilities by Count (balls,strikes)\", y=1.02)\n",
    "\n",
    "    for idx, (b, s) in enumerate(covs):\n",
    "        ax = axes[idx]\n",
    "        # one-hot に変換して π(s) を取得\n",
    "        x_input = encs[\"ohe_input\"].transform([[b, s]])\n",
    "        log_pi  = shmm_loaded.model_initial.predict_log_proba(x_input)[0]\n",
    "        pi      = np.exp(log_pi)\n",
    "\n",
    "        # プロット\n",
    "        ax.bar(state_ids, pi, color=f\"C{idx % 10}\")\n",
    "        ax.set_title(f\"b={b}, s={s}\", fontsize=12)\n",
    "        ax.set_xticks(state_ids)\n",
    "        ax.set_xticklabels(state_labels, rotation=0, fontsize=8)\n",
    "        ax.set_ylabel(\"π(s)\", fontsize=10)\n",
    "        ax.set_ylim(0, 1.0)\n",
    "        ax.yaxis.set_tick_params(labelsize=8)\n",
    "\n",
    "    # 余ったサブプロットを非表示に\n",
    "    for j in range(n_cov, n_rows * n_cols):\n",
    "        axes[j].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.98, 1.00])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef68dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "# クラスタ番号のリスト（必要に応じて変更）\n",
    "cluster_list = [0]  # すべてやりたいときは range(29) など\n",
    "\n",
    "# balls-strikes の全組み合わせ\n",
    "covs = [(b, s) for b in range(4) for s in range(3)]  # 4×3 = 12パターン\n",
    "\n",
    "for cluster in cluster_list:\n",
    "    model_dir = f\"iohmm_cluster_{cluster}_with_prior\"\n",
    "    model_fp = os.path.join(model_dir, \"model.pkl\")\n",
    "    enc_fp   = os.path.join(model_dir, \"encoders.pkl\")\n",
    "\n",
    "    if not os.path.isfile(model_fp):\n",
    "        print(f\"[Cluster {cluster}] モデルファイルが見つかりません ({model_fp})\")\n",
    "        continue\n",
    "    if not os.path.exists(enc_fp):\n",
    "        print(f\"[Cluster {cluster}] エンコーダーファイルが見つかりません: {enc_fp}\")\n",
    "        continue\n",
    "\n",
    "    with open(model_fp, \"rb\") as mf:\n",
    "        shmm_loaded = pickle.load(mf)\n",
    "    with open(enc_fp, \"rb\") as ef:\n",
    "        encs = pickle.load(ef)\n",
    "\n",
    "    # 隠れ状態のID と表示ラベル\n",
    "    n_states    = shmm_loaded.num_states\n",
    "    state_ids   = np.arange(n_states)\n",
    "    state_labels = [f\"state{st}\" for st in state_ids]\n",
    "\n",
    "    # グリッド図\n",
    "    fig, axes = plt.subplots(4, 3, figsize=(12, 12))\n",
    "    fig.suptitle(f\"Cluster {cluster} - Transition Probabilities\", y=1.02)\n",
    "\n",
    "    for idx, (b, s) in enumerate(covs):\n",
    "        ax = axes.flat[idx]\n",
    "\n",
    "        x_input = encs[\"ohe_input\"].transform([[b, s]])  # 条件をone-hotでエンコード\n",
    "\n",
    "        # 各状態から次状態への遷移確率\n",
    "        trans_mat = np.vstack([\n",
    "            np.exp(shmm_loaded.model_transition[st].predict_log_proba(x_input))\n",
    "            for st in state_ids\n",
    "        ])\n",
    "\n",
    "        im = ax.imshow(trans_mat, vmin=0, vmax=1, aspect='auto', cmap=cm.viridis)\n",
    "        ax.set_title(f\"balls={b}, strikes={s}\")\n",
    "        ax.set_xticks(state_ids)\n",
    "        ax.set_yticks(state_ids)\n",
    "        # X/Y 共に隠れ状態ラベルを表示\n",
    "        ax.set_xticklabels(state_labels, rotation=90, fontsize=6)\n",
    "        ax.set_yticklabels(state_labels,           fontsize=6)\n",
    "\n",
    "    # 共通カラーバー\n",
    "    cbar_ax = fig.add_axes([0.88, 0.15, 0.02, 0.7])\n",
    "    fig.colorbar(im, cax=cbar_ax, label=\"P(s' | s, balls, strikes)\")\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1.0])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c0305797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/share/fonts/truetype/noto/NotoSansMono-Regular.ttf\n",
      "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc\n",
      "/usr/share/fonts/opentype/noto/NotoSerifCJK-Bold.ttc\n",
      "/usr/share/fonts/opentype/noto/NotoSerifCJK-Black.ttc\n",
      "/usr/share/fonts/opentype/noto/NotoSansCJK-Medium.ttc\n",
      "/usr/share/fonts/truetype/noto/NotoSansMono-Bold.ttf\n",
      "/usr/share/fonts/opentype/noto/NotoSerifCJK-Light.ttc\n",
      "/usr/share/fonts/opentype/ipafont-gothic/ipagp.ttf\n",
      "/usr/share/fonts/opentype/ipafont-gothic/ipag.ttf\n",
      "/usr/share/fonts/truetype/noto/NotoMono-Regular.ttf\n",
      "/usr/share/fonts/opentype/noto/NotoSansCJK-Bold.ttc\n",
      "/usr/share/fonts/opentype/noto/NotoSansCJK-Light.ttc\n",
      "/usr/share/fonts/opentype/noto/NotoSansCJK-Black.ttc\n",
      "/usr/share/fonts/opentype/noto/NotoSerifCJK-Medium.ttc\n",
      "/usr/share/fonts/opentype/noto/NotoSerifCJK-Regular.ttc\n",
      "/usr/share/fonts/opentype/noto/NotoSansCJK-Thin.ttc\n",
      "/usr/share/fonts/truetype/noto/NotoColorEmoji.ttf\n",
      "/usr/share/fonts/opentype/noto/NotoSerifCJK-SemiBold.ttc\n",
      "/usr/share/fonts/opentype/noto/NotoSansCJK-DemiLight.ttc\n",
      "/usr/share/fonts/opentype/noto/NotoSerifCJK-ExtraLight.ttc\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.font_manager as fm\n",
    "\n",
    "for font in fm.findSystemFonts(fontpaths=None, fontext='ttf'):\n",
    "    if 'ipag' in font.lower() or 'noto' in font.lower():\n",
    "        print(font)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee70396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from math import ceil\n",
    "from matplotlib import font_manager as fm\n",
    "\n",
    "# --- 日本語フォント設定（お好みで） ---\n",
    "font_path = \"/usr/share/fonts/opentype/ipafont-gothic/ipag.ttf\"\n",
    "jp_font = fm.FontProperties(fname=font_path)\n",
    "plt.rcParams['font.family'] = jp_font.get_name()\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# クラスタリスト（任意で調整）\n",
    "cluster_list = [0]\n",
    "\n",
    "# balls-strikes 全パターン\n",
    "covs   = [(b, s) for b in range(4) for s in range(3)]\n",
    "n_cov  = len(covs)\n",
    "n_cols = 3\n",
    "n_rows = ceil(n_cov / n_cols)\n",
    "\n",
    "for cluster in cluster_list:\n",
    "    model_dir = f\"iohmm_cluster_{cluster}_with_prior\"\n",
    "    model_fp  = os.path.join(model_dir, \"model.pkl\")\n",
    "    enc_fp    = os.path.join(model_dir, \"encoders.pkl\")\n",
    "\n",
    "    if not os.path.isfile(model_fp) or not os.path.isfile(enc_fp):\n",
    "        print(f\"[Cluster {cluster}] モデルまたはエンコーダが見つかりません。スキップします。\")\n",
    "        continue\n",
    "\n",
    "    # モデルとエンコーダ読み込み\n",
    "    with open(model_fp, \"rb\") as mf:\n",
    "        shmm = pickle.load(mf)\n",
    "    with open(enc_fp, \"rb\") as ef:\n",
    "        encs = pickle.load(ef)\n",
    "\n",
    "    # ラベル類の準備\n",
    "    ohe         = encs[\"ohe_input\"]\n",
    "    pcl_labels  = encs[\"le_pitch_cluster_label\"].inverse_transform(np.arange(len(encs[\"le_pitch_cluster_label\"].classes_)))\n",
    "    zone_map    = {0:\"高め\",1:\"外角\",2:\"内角\",3:\"外角低め\",4:\"内角低め\"}\n",
    "    zcl_labels  = encs[\"le_zone_cluster\"].inverse_transform(np.arange(len(encs[\"le_zone_cluster\"].classes_)))\n",
    "    zcl_names   = [zone_map[int(lbl)] for lbl in zcl_labels]\n",
    "    # ← ここで隠れ状態ラベルを作成\n",
    "    state_ids   = np.arange(shmm.num_states)\n",
    "    state_labels= [f\"state{st}\" for st in state_ids]\n",
    "\n",
    "    # --- Emission0: pitch_cluster_label ---\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 4*n_rows), sharey=True)\n",
    "    axes = axes.flatten()\n",
    "    fig.suptitle(f\"Cluster {cluster} - Emission0: Pitch Cluster per (balls,strikes)\", y=1.02)\n",
    "\n",
    "    for i, (b, s) in enumerate(covs):\n",
    "        ax = axes[i]\n",
    "        x_input = ohe.transform([[b, s]])\n",
    "\n",
    "        # 各隠れ状態ごとの emission 確率行列を作成\n",
    "        emis0 = np.vstack([\n",
    "            np.exp(shmm.model_emissions[state][0].predict_log_proba(x_input)[0])\n",
    "            for state in state_ids\n",
    "        ])\n",
    "\n",
    "        im = ax.imshow(emis0, vmin=0, vmax=1, aspect='auto', cmap=cm.viridis)\n",
    "        ax.set_title(f\"b={b}, s={s}\")\n",
    "        # X 軸：pitch_cluster_label\n",
    "        ax.set_xticks(range(len(pcl_labels)))\n",
    "        ax.set_xticklabels(pcl_labels, rotation=90, fontsize=8)\n",
    "        # Y 軸：隠れ状態\n",
    "        ax.set_yticks(state_ids)\n",
    "        ax.set_yticklabels(state_labels, fontsize=8)\n",
    "        ax.set_xlabel(\"pitch_cluster_label\")\n",
    "        ax.set_ylabel(\"hidden state\")\n",
    "\n",
    "    for j in range(n_cov, len(axes)):\n",
    "        axes[j].axis(\"off\")\n",
    "\n",
    "    cbar_ax = fig.add_axes([0.88, 0.15, 0.02, 0.7])\n",
    "    fig.colorbar(im, cax=cbar_ax, label=\"P(y | state, cov)\")\n",
    "    plt.tight_layout(rect=[0,0,0.85,1.0])\n",
    "    plt.show()\n",
    "\n",
    "    # --- Emission1: zone_cluster ---\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 4*n_rows), sharey=True)\n",
    "    axes = axes.flatten()\n",
    "    fig.suptitle(f\"Cluster {cluster} - Emission1: Zone Cluster per (balls,strikes)\", y=1.02)\n",
    "\n",
    "    for i, (b, s) in enumerate(covs):\n",
    "        ax = axes[i]\n",
    "        x_input = ohe.transform([[b, s]])\n",
    "\n",
    "        emis1 = np.vstack([\n",
    "            np.exp(shmm.model_emissions[state][1].predict_log_proba(x_input)[0])\n",
    "            for state in state_ids\n",
    "        ])\n",
    "\n",
    "        im = ax.imshow(emis1, vmin=0, vmax=1, aspect='auto', cmap=cm.viridis)\n",
    "        ax.set_title(f\"b={b}, s={s}\")\n",
    "        # X 軸：zone_cluster\n",
    "        ax.set_xticks(range(len(zcl_names)))\n",
    "        ax.set_xticklabels(zcl_names, rotation=90, fontsize=8)\n",
    "        # Y 軸：隠れ状態\n",
    "        ax.set_yticks(state_ids)\n",
    "        ax.set_yticklabels(state_labels, fontsize=8)\n",
    "        ax.set_xlabel(\"zone_cluster\")\n",
    "        ax.set_ylabel(\"hidden state\")\n",
    "\n",
    "    for j in range(n_cov, len(axes)):\n",
    "        axes[j].axis(\"off\")\n",
    "\n",
    "    cbar_ax = fig.add_axes([0.88, 0.15, 0.02, 0.7])\n",
    "    fig.colorbar(im, cax=cbar_ax, label=\"P(y | state, cov)\")\n",
    "    plt.tight_layout(rect=[0,0,0.85,1.0])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5087a7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# 評価対象のクラスタリスト（必要に応じて調整）\n",
    "cluster_list = [0]\n",
    "\n",
    "for cluster in cluster_list:\n",
    "    dir_name = f\"iohmm_cluster_0_with_prior\"\n",
    "    model_file = os.path.join(dir_name, 'model.pkl')\n",
    "    test_file  = os.path.join(dir_name, 'test_data.csv')\n",
    "    enc_file   = os.path.join(dir_name, 'encoders.pkl')\n",
    "\n",
    "    if not all(os.path.exists(p) for p in [model_file, test_file, enc_file]):\n",
    "        print(f\"[Cluster {cluster}] ファイルが揃っていません。スキップします。\")\n",
    "        continue\n",
    "\n",
    "    with open(model_file, 'rb') as mf:\n",
    "        shmm = pickle.load(mf)\n",
    "    df_test = pd.read_csv(test_file)\n",
    "    with open(enc_file, 'rb') as ef:\n",
    "        encs = pickle.load(ef)\n",
    "\n",
    "    le_z   = encs['le_zone']\n",
    "    le_pcl = encs['le_pitch_cluster_label']\n",
    "    le_zcl = encs['le_zone_cluster']\n",
    "    ohe    = encs['ohe_input']\n",
    "\n",
    "    # game_pk ごとに系列を作成\n",
    "    test_dfs = []\n",
    "    for _, seq_df in df_test.groupby('game_pk'):\n",
    "        seq = seq_df.reset_index(drop=True)\n",
    "        test_dfs.append([seq, {}])\n",
    "\n",
    "    shmm.set_data(test_dfs)\n",
    "    shmm.E_step()\n",
    "    posterior_paths = [np.argmax(logg, axis=1) for logg in shmm.log_gammas]\n",
    "\n",
    "    hidden_true, hidden_pred = [], []\n",
    "    true_p, pred_p = [], []\n",
    "    true_z, pred_z = [], []\n",
    "\n",
    "    for (df, _), path in zip(test_dfs, posterior_paths):\n",
    "        hidden_true.extend(df['zone'].astype(int).values)\n",
    "        hidden_pred.extend(path)\n",
    "\n",
    "        X = ohe.transform(df[['balls','strikes']])\n",
    "        true_p.append(df['pitch_cluster_label'].values)\n",
    "        true_z.append(df['zone_cluster'].values)\n",
    "\n",
    "        pred_p_seq, pred_z_seq = [], []\n",
    "        for t, s in enumerate(path):\n",
    "            logp0 = shmm.model_emissions[s][0].predict_log_proba(X[t].reshape(1,-1))\n",
    "            pred_p_seq.append(int(np.argmax(np.exp(logp0))))\n",
    "\n",
    "            logp1 = shmm.model_emissions[s][1].predict_log_proba(X[t].reshape(1,-1))\n",
    "            pred_z_seq.append(int(np.argmax(np.exp(logp1))))\n",
    "\n",
    "        pred_p.append(np.array(pred_p_seq))\n",
    "        pred_z.append(np.array(pred_z_seq))\n",
    "\n",
    "    hidden_true = np.array(hidden_true)\n",
    "    hidden_pred = np.array(hidden_pred)\n",
    "    y_true_p = np.hstack(true_p)\n",
    "    y_pred_p = np.hstack(pred_p)\n",
    "    y_true_z = np.hstack(true_z)\n",
    "    y_pred_z = np.hstack(pred_z)\n",
    "\n",
    "    acc_hidden = accuracy_score(hidden_true, hidden_pred)\n",
    "    acc_p      = accuracy_score(y_true_p, y_pred_p)\n",
    "    acc_z      = accuracy_score(y_true_z, y_pred_z)\n",
    "\n",
    "    print(f\"[Cluster {cluster}] Hidden accuracy: {acc_hidden:.4f}\")\n",
    "    print(f\"[Cluster {cluster}] Pitch-cluster accuracy: {acc_p:.4f}\")\n",
    "    print(f\"[Cluster {cluster}] Zone-cluster accuracy:  {acc_z:.4f}\")\n",
    "\n",
    "    # 混同行列\n",
    "    cm_hidden = confusion_matrix(hidden_true, hidden_pred)\n",
    "    cm_pcl    = confusion_matrix(y_true_p, y_pred_p)\n",
    "    cm_zcl    = confusion_matrix(y_true_z, y_pred_z)\n",
    "\n",
    "    df_cm_hidden = pd.DataFrame(cm_hidden, index=le_z.classes_, columns=le_z.classes_)\n",
    "    df_cm_pcl    = pd.DataFrame(cm_pcl,    index=le_pcl.classes_, columns=le_pcl.classes_)\n",
    "    df_cm_zcl    = pd.DataFrame(cm_zcl,    index=le_zcl.classes_, columns=le_zcl.classes_)\n",
    "\n",
    "    # 保存\n",
    "    df_cm_hidden.to_csv(os.path.join(dir_name, 'cm_hidden_hot.csv'))\n",
    "    df_cm_pcl.to_csv(os.path.join(dir_name, 'cm_pitch_cluster_hot.csv'))\n",
    "    df_cm_zcl.to_csv(os.path.join(dir_name, 'cm_zone_cluster_hot.csv'))\n",
    "    with open(os.path.join(dir_name, 'evaluation_accuracy_hot.txt'), 'w') as outf:\n",
    "        outf.write(f\"hidden_state_accuracy: {acc_hidden:.4f}\\n\")\n",
    "        outf.write(f\"pitch_cluster_accuracy: {acc_p:.4f}\\n\")\n",
    "        outf.write(f\"zone_cluster_accuracy:  {acc_z:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5559285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "def viterbi_decode_iohmm(model, df, input_features, obs_features):\n",
    "    \"\"\"\n",
    "    model           : 学習済みの IOHMM オブジェクト\n",
    "    df              : pandas.DataFrame (ワンホット化済み input_features + 観測列を含む)\n",
    "    input_features  : list of str (ワンホット化後のカラム名リスト, encs['input_features'])\n",
    "    obs_features    : list of str (観測カラム名リスト, ['pitch_cluster_label','zone_cluster'])\n",
    "    \"\"\"\n",
    "    # --- 前処理 ---\n",
    "    X = df[input_features].values            # shape=(T, D)\n",
    "    T, N = len(df), model.num_states\n",
    "\n",
    "    # 初期モデルのログ確率 (t=0)\n",
    "    x0 = X[0].reshape(1, -1)\n",
    "    init = model.model_initial\n",
    "    if isinstance(init, list):\n",
    "        init = init[0]\n",
    "    log_pi = init.predict_log_proba(x0)[0]   # shape=(N,)\n",
    "\n",
    "    emis_models = model.model_emissions\n",
    "    trans_models = model.model_transition\n",
    "\n",
    "    # emission モデル構造判定\n",
    "    is_state_centric  = isinstance(emis_models, list) and isinstance(emis_models[0], list)\n",
    "    is_output_centric = isinstance(emis_models, list) and not is_state_centric\n",
    "\n",
    "    # Viterbi テーブル & ポインタ\n",
    "    log_delta = np.full((T, N), -np.inf)\n",
    "    psi       = np.zeros((T, N), dtype=int)\n",
    "\n",
    "    # --- t=0 の初期化 ---\n",
    "    for s in range(N):\n",
    "        score = log_pi[s]\n",
    "        for m, feat in enumerate(obs_features):\n",
    "            y0 = int(df[feat].iloc[0])\n",
    "            if is_state_centric:\n",
    "                em = emis_models[s][m]\n",
    "            elif is_output_centric:\n",
    "                em = emis_models[m][s]\n",
    "            else:\n",
    "                em = emis_models\n",
    "            score += em.predict_log_proba(x0)[0][y0]\n",
    "        log_delta[0, s] = score\n",
    "\n",
    "    # --- t>=1 の再帰ステップ ---\n",
    "    for t in range(1, T):\n",
    "        x_t = X[t].reshape(1, -1)\n",
    "        for s in range(N):\n",
    "            # 遷移スコア最大化\n",
    "            best_score, best_sp = -np.inf, 0\n",
    "            for sp in range(N):\n",
    "                tm = trans_models[sp] if isinstance(trans_models, list) else trans_models\n",
    "                log_a = tm.predict_log_proba(x_t)[0][s]\n",
    "                sc = log_delta[t-1, sp] + log_a\n",
    "                if sc > best_score:\n",
    "                    best_score, best_sp = sc, sp\n",
    "\n",
    "            # 観測エミッションを足し込む\n",
    "            total_e = 0.0\n",
    "            for m, feat in enumerate(obs_features):\n",
    "                y = int(df[feat].iloc[t])\n",
    "                if is_state_centric:\n",
    "                    em = emis_models[s][m]\n",
    "                elif is_output_centric:\n",
    "                    em = emis_models[m][s]\n",
    "                else:\n",
    "                    em = emis_models\n",
    "                total_e += em.predict_log_proba(x_t)[0][y]\n",
    "\n",
    "            log_delta[t, s] = best_score + total_e\n",
    "            psi[t, s]       = best_sp\n",
    "\n",
    "    # --- 逆追跡 ---\n",
    "    path = np.zeros(T, dtype=int)\n",
    "    path[-1] = np.argmax(log_delta[-1])\n",
    "    for t in range(T-2, -1, -1):\n",
    "        path[t] = psi[t+1, path[t+1]]\n",
    "\n",
    "    return path\n",
    "\n",
    "\n",
    "def evaluate_iohmm_with_viterbi(cluster_list, obs_features):\n",
    "    for cluster in cluster_list:\n",
    "        dir_name   = f\"iohmm_cluster_0_with_prior\"\n",
    "        model_file = os.path.join(dir_name, 'model.pkl')\n",
    "        test_file  = os.path.join(dir_name, 'test_data.csv')\n",
    "        enc_file   = os.path.join(dir_name, 'encoders.pkl')\n",
    "\n",
    "        if not all(os.path.exists(p) for p in [model_file, test_file, enc_file]):\n",
    "            print(f\"[Cluster {cluster}] ファイルが揃っていません。スキップします。\")\n",
    "            continue\n",
    "\n",
    "        # モデル・データ・エンコーダ読み込み\n",
    "        with open(model_file, 'rb') as mf:\n",
    "            shmm = pickle.load(mf)\n",
    "        df_test = pd.read_csv(test_file)\n",
    "        encs    = pickle.load(open(enc_file, 'rb'))\n",
    "\n",
    "        input_features = encs['input_features']  # ワンホット化後のカラム名リスト\n",
    "\n",
    "        # 投手＋試合ごとに系列分割\n",
    "        test_seqs = [\n",
    "            g.reset_index(drop=True)\n",
    "            for _, g in df_test.groupby(['pitcher','game_pk'])\n",
    "        ]\n",
    "\n",
    "        all_true_p, all_pred_p = [], []\n",
    "        all_true_z, all_pred_z = [], []\n",
    "\n",
    "        for seq in test_seqs:\n",
    "            path = viterbi_decode_iohmm(\n",
    "                model=shmm,\n",
    "                df=seq,\n",
    "                input_features=input_features,\n",
    "                obs_features=obs_features\n",
    "            )\n",
    "\n",
    "            X = seq[input_features].values\n",
    "            # 真ラベルを収集\n",
    "            all_true_p.append(seq['pitch_cluster_label'].astype(int).values)\n",
    "            all_true_z.append(seq['zone_cluster'].astype(int).values)\n",
    "\n",
    "            # 予測を収集\n",
    "            pred_p, pred_z = [], []\n",
    "            for t, s in enumerate(path):\n",
    "                logp0 = shmm.model_emissions[s][0].predict_log_proba(X[t].reshape(1, -1))[0]\n",
    "                pred_p.append(int(np.argmax(logp0)))\n",
    "                logp1 = shmm.model_emissions[s][1].predict_log_proba(X[t].reshape(1, -1))[0]\n",
    "                pred_z.append(int(np.argmax(logp1)))\n",
    "\n",
    "            all_pred_p.append(np.array(pred_p))\n",
    "            all_pred_z.append(np.array(pred_z))\n",
    "\n",
    "        # フラット化して精度算出\n",
    "        y_true_p = np.hstack(all_true_p)\n",
    "        y_pred_p = np.hstack(all_pred_p)\n",
    "        y_true_z = np.hstack(all_true_z)\n",
    "        y_pred_z = np.hstack(all_pred_z)\n",
    "\n",
    "        print(f\"[Cluster {cluster}] Pitch-cluster accuracy: {accuracy_score(y_true_p, y_pred_p):.4f}\")\n",
    "        print(f\"[Cluster {cluster}] Zone-cluster accuracy:  {accuracy_score(y_true_z, y_pred_z):.4f}\")\n",
    "\n",
    "        # 混同行列も保存\n",
    "        cm_pcl = pd.DataFrame(confusion_matrix(y_true_p, y_pred_p))\n",
    "        cm_zcl = pd.DataFrame(confusion_matrix(y_true_z, y_pred_z))\n",
    "        cm_pcl.to_csv(os.path.join(dir_name, 'cm_pitch_cluster_viterbi.csv'), index=True)\n",
    "        cm_zcl.to_csv(os.path.join(dir_name, 'cm_zone_cluster_viterbi.csv'), index=True)\n",
    "\n",
    "# ── 実行 ──\n",
    "evaluate_iohmm_with_viterbi(\n",
    "    cluster_list=[0],\n",
    "    obs_features=['pitch_cluster_label', 'zone_cluster']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148ea611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "# Zone Cluster の日本語名マップ\n",
    "zone_names = {\n",
    "    0: \"高め\",\n",
    "    1: \"外角\",\n",
    "    2: \"内角\",\n",
    "    3: \"外角低め\",\n",
    "    4: \"内角低め\"\n",
    "}\n",
    "\n",
    "# 評価対象のクラスタリスト\n",
    "cluster_list = [0]\n",
    "\n",
    "# 混同行列ファイルのマッピング\n",
    "matrix_files = {\n",
    "    \"Pitch Cluster\":   \"cm_pitch_cluster_hot.csv\",\n",
    "    \"Zone Cluster\":    \"cm_zone_cluster_hot.csv\"\n",
    "}\n",
    "\n",
    "# 日本語フォントの指定（適宜環境に応じて変更）\n",
    "jp_font = FontProperties(fname='/usr/share/fonts/opentype/noto/NotoSansCJK-DemiLight.ttc')\n",
    "rcParams['font.family'] = jp_font.get_name()\n",
    "rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "for cluster in cluster_list:\n",
    "    dir_name = f\"iohmm_cluster_0_with_prior\"\n",
    "    for title, filename in matrix_files.items():\n",
    "        path = os.path.join(dir_name, filename)\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"[Cluster {cluster}] {filename} が見つかりません。スキップします。\")\n",
    "            continue\n",
    "\n",
    "        df_cm = pd.read_csv(path, index_col=0)\n",
    "        df_prop = df_cm.div(df_cm.sum(axis=1), axis=0).fillna(0)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        im = ax.imshow(df_prop.values, aspect='auto', cmap='Blues')\n",
    "        plt.colorbar(im, ax=ax)\n",
    "\n",
    "        # 軸ラベル設定\n",
    "        if title == \"Zone Cluster\":\n",
    "            x_labels = [zone_names.get(int(c), str(c)) for c in df_prop.columns]\n",
    "            y_labels = [zone_names.get(int(c), str(c)) for c in df_prop.index]\n",
    "        else:\n",
    "            x_labels = [str(c) for c in df_prop.columns]\n",
    "            y_labels = [str(c) for c in df_prop.index]\n",
    "\n",
    "        ax.set_xticks(range(len(x_labels)))\n",
    "        ax.set_xticklabels(x_labels, rotation=90)\n",
    "        ax.set_yticks(range(len(y_labels)))\n",
    "        ax.set_yticklabels(y_labels)\n",
    "\n",
    "        ax.set_xlabel(\"Predicted\")\n",
    "        ax.set_ylabel(\"True\")\n",
    "        ax.set_title(f\"Cluster {cluster} - {title} (Probability)\")\n",
    "\n",
    "        # 数値注記\n",
    "        for i in range(df_prop.shape[0]):\n",
    "            for j in range(df_prop.shape[1]):\n",
    "                ax.text(j, i, f\"{df_prop.iat[i,j]:.2f}\",\n",
    "                        ha=\"center\", va=\"center\", fontsize='small', color='black')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d906293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "# Zone Cluster の日本語名マップ\n",
    "zone_names = {\n",
    "    0: \"高め\",\n",
    "    1: \"外角\",\n",
    "    2: \"内角\",\n",
    "    3: \"外角低め\",\n",
    "    4: \"内角低め\"\n",
    "}\n",
    "\n",
    "pitch_names = {\n",
    "    0:\"CH\",\n",
    "    1:\"CU\",\n",
    "    2:\"FF/FC\",\n",
    "    3:\"FF/SI\",\n",
    "    4:\"SL\"\n",
    "}\n",
    "\n",
    "# 評価対象のクラスタリスト\n",
    "cluster_list = [0]\n",
    "\n",
    "# 混同行列ファイルのマッピング\n",
    "matrix_files = {\n",
    "    \"Pitch Cluster\":   \"cm_pitch_cluster_viterbi.csv\",\n",
    "    \"Zone Cluster\":    \"cm_zone_cluster_viterbi.csv\"\n",
    "}\n",
    "\n",
    "# 日本語フォントの指定（適宜環境に応じて変更）\n",
    "jp_font = FontProperties(fname='/usr/share/fonts/opentype/noto/NotoSansCJK-DemiLight.ttc')\n",
    "rcParams['font.family'] = jp_font.get_name()\n",
    "rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "for cluster in cluster_list:\n",
    "    dir_name = f\"iohmm_cluster_0_with_prior\"\n",
    "    for title, filename in matrix_files.items():\n",
    "        path = os.path.join(dir_name, filename)\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"[Cluster {cluster}] {filename} が見つかりません。スキップします。\")\n",
    "            continue\n",
    "\n",
    "        df_cm = pd.read_csv(path, index_col=0)\n",
    "        df_prop = df_cm.div(df_cm.sum(axis=1), axis=0).fillna(0)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        im = ax.imshow(df_prop.values, aspect='auto', cmap='Blues')\n",
    "        plt.colorbar(im, ax=ax)\n",
    "\n",
    "        # 軸ラベル設定\n",
    "        if title == \"Zone Cluster\":\n",
    "            x_labels = [zone_names.get(int(c), str(c)) for c in df_prop.columns]\n",
    "            y_labels = [zone_names.get(int(c), str(c)) for c in df_prop.index]\n",
    "        elif title == \"Pitch Cluster\":\n",
    "            x_labels = [pitch_names.get(int(c), str(c)) for c in df_prop.columns]\n",
    "            y_labels = [pitch_names.get(int(c), str(c)) for c in df_prop.index]\n",
    "        else:\n",
    "            x_labels = [str(c) for c in df_prop.columns]\n",
    "            y_labels = [str(c) for c in df_prop.index]\n",
    "\n",
    "        ax.set_xticks(range(len(x_labels)))\n",
    "        ax.set_xticklabels(x_labels, rotation=90)\n",
    "        ax.set_yticks(range(len(y_labels)))\n",
    "        ax.set_yticklabels(y_labels)\n",
    "\n",
    "        ax.set_xlabel(\"Predicted\")\n",
    "        ax.set_ylabel(\"True\")\n",
    "        ax.set_title(f\"Cluster {cluster} - {title} (Probability)\")\n",
    "\n",
    "        # 数値注記\n",
    "        for i in range(df_prop.shape[0]):\n",
    "            for j in range(df_prop.shape[1]):\n",
    "                ax.text(j, i, f\"{df_prop.iat[i,j]:.2f}\",\n",
    "                        ha=\"center\", va=\"center\", fontsize='small', color='black')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d11dcdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
